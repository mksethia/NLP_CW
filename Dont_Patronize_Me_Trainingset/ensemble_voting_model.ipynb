{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86574cff",
   "metadata": {},
   "source": [
    "# Ensemble Voting Model ‚Äî Don't Patronize Me!\n",
    "\n",
    "**Binary PCL classification** using RoBERTa, DistilBERT, and DeBERTa with majority-vote ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744fa19b",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "563b2b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azureuser/nlp/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version : 2.10.0+cu128\n",
      "CUDA available  : True\n",
      "GPU device      : Tesla T4\n",
      "GPU memory      : 15.6 GB\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    ConfusionMatrixDisplay,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "import gc\n",
    "\n",
    "print(f\"PyTorch version : {torch.__version__}\")\n",
    "print(f\"CUDA available  : {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU device      : {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory      : {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9a9ee6",
   "metadata": {},
   "source": [
    "## 2. Device Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "929e9362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device    : cuda\n",
      "bf16 supported  : True\n",
      "Class weights   : tensor([1., 9.], device='cuda:0')  (device: cuda:0)\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_LABELS = 2\n",
    "LABEL_NAMES = [\"Non-PCL\", \"PCL\"]\n",
    "\n",
    "# Class weights for the ~9.5:1 imbalance (Non-PCL : PCL).\n",
    "# Placing on DEVICE once avoids repeated .to() calls inside compute_loss.\n",
    "CLASS_WEIGHTS = torch.tensor([1.0, 9.0], dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "# Mixed-precision strategy:\n",
    "#   bf16 preferred (Ampere+ GPUs) ‚Äî works with all models including DeBERTa v3.\n",
    "#   fp16 as fallback for older GPUs ‚Äî but NOT safe for DeBERTa v3 (FP16 gradient error).\n",
    "_BF16_OK = torch.cuda.is_available() and torch.cuda.is_bf16_supported()\n",
    "\n",
    "print(f\"Using device    : {DEVICE}\")\n",
    "print(f\"bf16 supported  : {_BF16_OK}\")\n",
    "print(f\"Class weights   : {CLASS_WEIGHTS}  (device: {CLASS_WEIGHTS.device})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03df6c65",
   "metadata": {},
   "source": [
    "## 3. Load & Preprocess Dataset\n",
    "\n",
    "Binary labels as per the paper: labels 0-1 ‚Üí **Non-PCL (0)**, labels 2-4 ‚Üí **PCL (1)**.\n",
    "\n",
    "We split 80/10/10 into train / val / test. The test set is held out entirely until final evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ef6cbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples  : 10468\n",
      "Label distribution:\n",
      "binary_label\n",
      "Non-PCL    9475\n",
      "PCL         993\n",
      "Name: count, dtype: int64\n",
      "Imbalance ratio: 9.54:1\n",
      "\n",
      "Split sizes ‚Äî train: 8374, val: 1047, test: 1047\n"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    \"\"\"Load Don't Patronize Me PCL dataset and binarise labels.\"\"\"\n",
    "    pcl_columns = [\"par_id\", \"art_id\", \"keyword\", \"country_code\", \"text\", \"label\"]\n",
    "    df = pd.read_csv(\n",
    "        \"dontpatronizeme_pcl.tsv\",\n",
    "        sep=\"\\t\",\n",
    "        skiprows=4,\n",
    "        names=pcl_columns,\n",
    "        on_bad_lines=\"skip\",\n",
    "        engine=\"python\",\n",
    "    )\n",
    "\n",
    "    # Drop rows with missing text or labels\n",
    "    df = df.dropna(subset=[\"text\", \"label\"])\n",
    "    df[\"label\"] = df[\"label\"].astype(int)\n",
    "\n",
    "    # Binary: 0-1 ‚Üí Non-PCL (0),  2-4 ‚Üí PCL (1)\n",
    "    df[\"binary_label\"] = (df[\"label\"] >= 2).astype(int)\n",
    "\n",
    "    print(f\"Total samples  : {len(df)}\")\n",
    "    print(f\"Label distribution:\\n{df['binary_label'].value_counts().rename({0: 'Non-PCL', 1: 'PCL'})}\")\n",
    "    print(f\"Imbalance ratio: {(df['binary_label'] == 0).sum() / (df['binary_label'] == 1).sum():.2f}:1\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = load_data()\n",
    "\n",
    "# 80 / 10 / 10 stratified split\n",
    "train_df, temp_df = train_test_split(\n",
    "    df, test_size=0.2, stratify=df[\"binary_label\"], random_state=42\n",
    ")\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df, test_size=0.5, stratify=temp_df[\"binary_label\"], random_state=42\n",
    ")\n",
    "\n",
    "# Convert to HuggingFace Datasets\n",
    "train_dataset = Dataset.from_dict({\"text\": train_df[\"text\"].tolist(), \"label\": train_df[\"binary_label\"].tolist()})\n",
    "val_dataset   = Dataset.from_dict({\"text\": val_df[\"text\"].tolist(),   \"label\": val_df[\"binary_label\"].tolist()})\n",
    "test_dataset  = Dataset.from_dict({\"text\": test_df[\"text\"].tolist(),  \"label\": test_df[\"binary_label\"].tolist()})\n",
    "\n",
    "print(f\"\\nSplit sizes ‚Äî train: {len(train_dataset)}, val: {len(val_dataset)}, test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0aa4b3",
   "metadata": {},
   "source": [
    "## 4. Model Definitions & Tokenisation\n",
    "\n",
    "We define:\n",
    "- **Model catalogue** ‚Äî three transformer architectures\n",
    "- **`WeightedTrainer`** ‚Äî custom Trainer that uses class-weighted CrossEntropyLoss. The class weights tensor is moved to device **once** (at init), not on every forward pass.\n",
    "- **`compute_metrics`** ‚Äî accuracy, precision, recall, F1\n",
    "- Per-model tokenisation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4bccf98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tokeniser for RoBERTa\n",
      "Loaded tokeniser for DistilBERT\n",
      "Loaded tokeniser for DeBERTa\n"
     ]
    }
   ],
   "source": [
    "MODEL_CATALOGUE = {\n",
    "    \"RoBERTa\":    \"FacebookAI/roberta-base\",\n",
    "    \"DistilBERT\": \"distilbert-base-uncased\",\n",
    "    \"DeBERTa\":    \"microsoft/deberta-v3-base\",\n",
    "}\n",
    "\n",
    "MAX_LENGTH = 128  # EDA: median 42 word tokens, 95th pct ~105; subword inflation ~1.3x ‚Üí 128 is safe\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Mixed-precision helper ‚Äî decides fp16 vs bf16 per model\n",
    "# ---------------------------------------------------------------------------\n",
    "def get_mixed_precision_flags(model_name: str):\n",
    "    \"\"\"Return (fp16, bf16) flags for a given model.\n",
    "\n",
    "    ‚Ä¢ bf16 is preferred for ALL models when the GPU supports it (Ampere+).\n",
    "    ‚Ä¢ fp16 is used as fallback ‚Äî except for DeBERTa v3 which produces\n",
    "      gradient-unscale errors under fp16.\n",
    "    ‚Ä¢ DeBERTa v3 falls back to fp32 if bf16 is unavailable.\n",
    "    \"\"\"\n",
    "    # if _BF16_OK:\n",
    "    #     return False, True          # bf16 for everything\n",
    "    # if model_name == \"DeBERTa\":\n",
    "    #     return False, False         # fp32 fallback (fp16 is unsafe)\n",
    "    # if torch.cuda.is_available():\n",
    "    #     return True, False          # fp16 for other models\n",
    "    return False, False             # Generic fallback\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Weighted Trainer ‚Äî class weights live on the same device as the model\n",
    "# ---------------------------------------------------------------------------\n",
    "class WeightedTrainer(Trainer):\n",
    "    \"\"\"Trainer that applies class weights to CrossEntropyLoss.\n",
    "\n",
    "    Supports per-trial class_weight_pos override via self.args (set by\n",
    "    Optuna hp search). Falls back to the weights passed at init.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, class_weights: torch.Tensor, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._class_weights = class_weights\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # ---- NaN guard: clamp logits to prevent NaN propagation ----------\n",
    "        # if torch.isnan(logits).any() or torch.isinf(logits).any():\n",
    "        #     logits = torch.nan_to_num(logits, nan=0.0, posinf=1e4, neginf=-1e4)\n",
    "\n",
    "        # Use per-trial class_weight_pos if set by hp search, else default\n",
    "        pos_w = getattr(self.args, \"class_weight_pos\", None)\n",
    "        if pos_w is not None:\n",
    "            weights = torch.tensor([1.0, pos_w], dtype=logits.dtype, device=logits.device)\n",
    "        else:\n",
    "            weights = self._class_weights.to(dtype=logits.dtype, device=logits.device)\n",
    "            \n",
    "        loss_fn = nn.CrossEntropyLoss(weight=weights, reduction=\"mean\")\n",
    "        loss = loss_fn(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Metrics\n",
    "# ---------------------------------------------------------------------------\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Compute accuracy, precision, recall, F1 for the positive class (PCL).\"\"\"\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, average=\"binary\", pos_label=1, zero_division=0\n",
    "    )\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Tokenisers ‚Äî NO padding here; DataCollatorWithPadding pads per-batch\n",
    "# (median text ~42 tokens ‚Üí dynamic padding is ~2x faster than pad-to-128)\n",
    "# ---------------------------------------------------------------------------\n",
    "tokenisers = {}\n",
    "for name, path in MODEL_CATALOGUE.items():\n",
    "    tokenisers[name] = AutoTokenizer.from_pretrained(path)\n",
    "    print(f\"Loaded tokeniser for {name}\")\n",
    "\n",
    "\n",
    "def tokenize_dataset(dataset, tokenizer):\n",
    "    \"\"\"Tokenise a HuggingFace Dataset with the given tokenizer (no padding).\"\"\"\n",
    "    def _tok(examples):\n",
    "        return tokenizer(\n",
    "            examples[\"text\"], truncation=True, max_length=MAX_LENGTH\n",
    "        )\n",
    "    return dataset.map(_tok, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0685a9f0",
   "metadata": {},
   "source": [
    "## 5. Bayesian Hyperparameter Optimisation (Optuna)\n",
    "\n",
    "For each model we run `trainer.hyperparameter_search` with an Optuna backend. This performs **Bayesian optimisation** (Tree-structured Parzen Estimator by default) over learning rate, number of epochs, batch size, weight decay, and **class weight for PCL** (searched 8‚Äì10 around the ~9.5:1 natural ratio).\n",
    "\n",
    "Key design decisions:\n",
    "- **`model_init`** function (not a pre-built model) so Trainer can reinitialise fresh weights each trial\n",
    "- **`class_weight_pos`** in the search space ‚Äî the most impactful knob for imbalanced classification\n",
    "- **Dynamic padding** (`DataCollatorWithPadding`) ‚Äî pads per-batch instead of to `MAX_LENGTH`, ~2√ó faster\n",
    "- **DeBERTa v3** uses `bf16` (or fp32 fallback) instead of `fp16` which causes gradient unscale errors\n",
    "- `direction=\"maximize\"` because we optimise F1\n",
    "\n",
    "Set `USE_PREVIOUS_HPARAMS` per-model in the cell below to **load saved results** from `best_hparams.json` or **re-run** the Optuna search (which overwrites the file on completion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb197ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ Toggle: reuse saved hyperparameters or re-run Optuna search ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# Set per-model: True  = load from best_hparams.json (fast, no GPU needed)\n",
    "#                False = run Bayesian HP search with Optuna (overwrites file)\n",
    "\n",
    "HPARAMS_FILE = Path(\"best_hparams.json\")\n",
    "\n",
    "USE_PREVIOUS_HPARAMS = {\n",
    "    \"RoBERTa\":    True,\n",
    "    \"DistilBERT\": True,\n",
    "    \"DeBERTa\":    False,\n",
    "}\n",
    "\n",
    "N_TRIALS = 10\n",
    "\n",
    "\n",
    "# 1. Load existing registry (or start fresh if missing)\n",
    "hparams_registry = {}\n",
    "if HPARAMS_FILE.exists():\n",
    "    with open(HPARAMS_FILE) as f:\n",
    "        hparams_registry = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2f50ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ RoBERTa      | Loading saved (F1: 0.4789)\n",
      "üìÇ DistilBERT   | Loading saved (F1: 0.3947)\n",
      "\n",
      "========================================\n",
      "üîç Searching: DeBERTa\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8374/8374 [00:00<00:00, 10986.59 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1047/1047 [00:00<00:00, 14881.13 examples/s]\n",
      "Loading weights: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 198/198 [00:00<00:00, 1101.52it/s, Materializing param=deberta.encoder.rel_embeddings.weight]                     \n",
      "\u001b[1mDebertaV2ForSequenceClassification LOAD REPORT\u001b[0m from: microsoft/deberta-v3-base\n",
      "Key                                     | Status     | \n",
      "----------------------------------------+------------+-\n",
      "lm_predictions.lm_head.dense.bias       | UNEXPECTED | \n",
      "mask_predictions.LayerNorm.weight       | UNEXPECTED | \n",
      "mask_predictions.LayerNorm.bias         | UNEXPECTED | \n",
      "lm_predictions.lm_head.LayerNorm.weight | UNEXPECTED | \n",
      "lm_predictions.lm_head.dense.weight     | UNEXPECTED | \n",
      "mask_predictions.classifier.bias        | UNEXPECTED | \n",
      "mask_predictions.classifier.weight      | UNEXPECTED | \n",
      "lm_predictions.lm_head.bias             | UNEXPECTED | \n",
      "lm_predictions.lm_head.LayerNorm.bias   | UNEXPECTED | \n",
      "mask_predictions.dense.bias             | UNEXPECTED | \n",
      "mask_predictions.dense.weight           | UNEXPECTED | \n",
      "pooler.dense.weight                     | MISSING    | \n",
      "pooler.dense.bias                       | MISSING    | \n",
      "classifier.weight                       | MISSING    | \n",
      "classifier.bias                         | MISSING    | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n",
      "\u001b[32m[I 2026-02-11 12:48:05,169]\u001b[0m A new study created in memory with name: no-name-afbfc33b-3af5-45e8-b671-d0d8af1cac56\u001b[0m\n",
      "Trying to set class_weight_pos in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n",
      "Loading weights: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 198/198 [00:00<00:00, 1088.43it/s, Materializing param=deberta.encoder.rel_embeddings.weight]                     \n",
      "\u001b[1mDebertaV2ForSequenceClassification LOAD REPORT\u001b[0m from: microsoft/deberta-v3-base\n",
      "Key                                     | Status     | \n",
      "----------------------------------------+------------+-\n",
      "lm_predictions.lm_head.dense.bias       | UNEXPECTED | \n",
      "mask_predictions.LayerNorm.weight       | UNEXPECTED | \n",
      "mask_predictions.LayerNorm.bias         | UNEXPECTED | \n",
      "lm_predictions.lm_head.LayerNorm.weight | UNEXPECTED | \n",
      "lm_predictions.lm_head.dense.weight     | UNEXPECTED | \n",
      "mask_predictions.classifier.bias        | UNEXPECTED | \n",
      "mask_predictions.classifier.weight      | UNEXPECTED | \n",
      "lm_predictions.lm_head.bias             | UNEXPECTED | \n",
      "lm_predictions.lm_head.LayerNorm.bias   | UNEXPECTED | \n",
      "mask_predictions.dense.bias             | UNEXPECTED | \n",
      "mask_predictions.dense.weight           | UNEXPECTED | \n",
      "pooler.dense.weight                     | MISSING    | \n",
      "pooler.dense.bias                       | MISSING    | \n",
      "classifier.weight                       | MISSING    | \n",
      "classifier.bias                         | MISSING    | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n",
      "\u001b[33m[W 2026-02-11 12:48:30,968]\u001b[0m Trial 0 failed with parameters: {'learning_rate': 5.61682898839319e-06, 'weight_decay': 0.074874246774961, 'batch_size': 32, 'class_weight_pos': 3.5771099728956552} because of the following error: KeyboardInterrupt().\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/azureuser/nlp/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 206, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/home/azureuser/nlp/.venv/lib/python3.12/site-packages/transformers/integrations/integration_utils.py\", line 253, in _objective\n",
      "    trainer.train(resume_from_checkpoint=checkpoint, trial=trial)\n",
      "  File \"/home/azureuser/nlp/.venv/lib/python3.12/site-packages/transformers/trainer.py\", line 2170, in train\n",
      "    return inner_training_loop(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/azureuser/nlp/.venv/lib/python3.12/site-packages/transformers/trainer.py\", line 2481, in _inner_training_loop\n",
      "    batch_samples, num_items_in_batch = self.get_batch_samples(epoch_iterator, num_batches, args.device)\n",
      "                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/azureuser/nlp/.venv/lib/python3.12/site-packages/transformers/trainer.py\", line 5246, in get_batch_samples\n",
      "    batch_samples.append(next(epoch_iterator))\n",
      "                         ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/azureuser/nlp/.venv/lib/python3.12/site-packages/accelerate/data_loader.py\", line 577, in __iter__\n",
      "    current_batch = send_to_device(current_batch, self.device, non_blocking=self._non_blocking)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/azureuser/nlp/.venv/lib/python3.12/site-packages/accelerate/utils/operations.py\", line 154, in send_to_device\n",
      "    return tensor.to(device, non_blocking=non_blocking)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/azureuser/nlp/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py\", line 774, in to\n",
      "    k: v.to(device=device, non_blocking=non_blocking) if hasattr(v, \"to\") and callable(v.to) else v\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "\u001b[33m[W 2026-02-11 12:48:30,971]\u001b[0m Trial 0 failed with value None.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 60\u001b[39m\n\u001b[32m     39\u001b[39m training_args = TrainingArguments(\n\u001b[32m     40\u001b[39m     output_dir=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m./results/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     41\u001b[39m     eval_strategy=\u001b[33m\"\u001b[39m\u001b[33mepoch\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     47\u001b[39m     disable_tqdm=\u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;66;03m# Cleaner logs during HP search\u001b[39;00m\n\u001b[32m     48\u001b[39m )\n\u001b[32m     50\u001b[39m trainer = WeightedTrainer(\n\u001b[32m     51\u001b[39m     model_init=\u001b[38;5;28;01mlambda\u001b[39;00m: AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=NUM_LABELS),\n\u001b[32m     52\u001b[39m     args=training_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m     57\u001b[39m     class_weights=CLASS_WEIGHTS,\n\u001b[32m     58\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m best_run = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhyperparameter_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdirection\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moptuna\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhp_space\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptuna_hp_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mN_TRIALS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpruner\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMedianPruner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_startup_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompute_objective\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meval_f1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[38;5;66;03m# Store results\u001b[39;00m\n\u001b[32m     70\u001b[39m best_hparams[name] = best_run.hyperparameters\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/nlp/.venv/lib/python3.12/site-packages/transformers/trainer.py:3554\u001b[39m, in \u001b[36mTrainer.hyperparameter_search\u001b[39m\u001b[34m(self, hp_space, compute_objective, n_trials, direction, backend, hp_name, **kwargs)\u001b[39m\n\u001b[32m   3551\u001b[39m \u001b[38;5;28mself\u001b[39m.hp_name = hp_name\n\u001b[32m   3552\u001b[39m \u001b[38;5;28mself\u001b[39m.compute_objective = default_compute_objective \u001b[38;5;28;01mif\u001b[39;00m compute_objective \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m compute_objective\n\u001b[32m-> \u001b[39m\u001b[32m3554\u001b[39m best_run = \u001b[43mbackend_obj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3556\u001b[39m \u001b[38;5;28mself\u001b[39m.hp_search_backend = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   3557\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m best_run\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/nlp/.venv/lib/python3.12/site-packages/transformers/hyperparameter_search.py:68\u001b[39m, in \u001b[36mOptunaBackend.run\u001b[39m\u001b[34m(self, trainer, n_trials, direction, **kwargs)\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, trainer, n_trials: \u001b[38;5;28mint\u001b[39m, direction: \u001b[38;5;28mstr\u001b[39m, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_hp_search_optuna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/nlp/.venv/lib/python3.12/site-packages/transformers/integrations/integration_utils.py:272\u001b[39m, in \u001b[36mrun_hp_search_optuna\u001b[39m\u001b[34m(trainer, n_trials, direction, **kwargs)\u001b[39m\n\u001b[32m    270\u001b[39m direction = \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m directions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m direction\n\u001b[32m    271\u001b[39m study = optuna.create_study(direction=direction, directions=directions, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_objective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcatch\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m study._is_multi_objective():\n\u001b[32m    276\u001b[39m     best_trial = study.best_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/nlp/.venv/lib/python3.12/site-packages/optuna/study/study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/nlp/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:68\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     81\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/nlp/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:165\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    162\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    170\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    171\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/nlp/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:263\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    256\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    259\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    260\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    261\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    262\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m263\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/nlp/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:206\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    208\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    209\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/nlp/.venv/lib/python3.12/site-packages/transformers/integrations/integration_utils.py:253\u001b[39m, in \u001b[36mrun_hp_search_optuna.<locals>._objective\u001b[39m\u001b[34m(trial, checkpoint_dir)\u001b[39m\n\u001b[32m    251\u001b[39m     trainer.train(resume_from_checkpoint=checkpoint, trial=trial)\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;66;03m# If there hasn't been any evaluation during the training loop.\u001b[39;00m\n\u001b[32m    255\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(trainer, \u001b[33m\"\u001b[39m\u001b[33mobjective\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/nlp/.venv/lib/python3.12/site-packages/transformers/trainer.py:2170\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2168\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2169\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2170\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2171\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2172\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2173\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2174\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2175\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/nlp/.venv/lib/python3.12/site-packages/transformers/trainer.py:2481\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2479\u001b[39m update_step += \u001b[32m1\u001b[39m\n\u001b[32m   2480\u001b[39m num_batches = args.gradient_accumulation_steps \u001b[38;5;28;01mif\u001b[39;00m update_step != (total_updates - \u001b[32m1\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m remainder\n\u001b[32m-> \u001b[39m\u001b[32m2481\u001b[39m batch_samples, num_items_in_batch = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_batch_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2482\u001b[39m \u001b[38;5;66;03m# Store the number of batches for current gradient accumulation\u001b[39;00m\n\u001b[32m   2483\u001b[39m \u001b[38;5;66;03m# This is used to correctly scale the loss when the last accumulation step has fewer batches\u001b[39;00m\n\u001b[32m   2484\u001b[39m \u001b[38;5;28mself\u001b[39m.current_gradient_accumulation_steps = \u001b[38;5;28mlen\u001b[39m(batch_samples)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/nlp/.venv/lib/python3.12/site-packages/transformers/trainer.py:5246\u001b[39m, in \u001b[36mTrainer.get_batch_samples\u001b[39m\u001b[34m(self, epoch_iterator, num_batches, device)\u001b[39m\n\u001b[32m   5244\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches):\n\u001b[32m   5245\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m5246\u001b[39m         batch_samples.append(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   5247\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m   5248\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/nlp/.venv/lib/python3.12/site-packages/accelerate/data_loader.py:577\u001b[39m, in \u001b[36mDataLoaderShard.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    574\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    575\u001b[39m     \u001b[38;5;66;03m# But we still move it to the device so it is done before `StopIteration` is reached\u001b[39;00m\n\u001b[32m    576\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m577\u001b[39m         current_batch = \u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_non_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    578\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_state_dict()\n\u001b[32m    579\u001b[39m     next_batch = \u001b[38;5;28mnext\u001b[39m(dataloader_iter)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/nlp/.venv/lib/python3.12/site-packages/accelerate/utils/operations.py:154\u001b[39m, in \u001b[36msend_to_device\u001b[39m\u001b[34m(tensor, device, non_blocking, skip_keys)\u001b[39m\n\u001b[32m    152\u001b[39m     device = \u001b[33m\"\u001b[39m\u001b[33mnpu:0\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# .to() doesn't accept non_blocking as kwarg\u001b[39;00m\n\u001b[32m    156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor.to(device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/nlp/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:774\u001b[39m, in \u001b[36mBatchEncoding.to\u001b[39m\u001b[34m(self, device, non_blocking)\u001b[39m\n\u001b[32m    769\u001b[39m \u001b[38;5;66;03m# This check catches things like APEX blindly calling \"to\" on all inputs to a module\u001b[39;00m\n\u001b[32m    770\u001b[39m \u001b[38;5;66;03m# Otherwise it passes the casts down and casts the LongTensor containing the token idxs\u001b[39;00m\n\u001b[32m    771\u001b[39m \u001b[38;5;66;03m# into a HalfTensor\u001b[39;00m\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m is_torch_device(device) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mint\u001b[39m):\n\u001b[32m    773\u001b[39m     \u001b[38;5;28mself\u001b[39m.data = {\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m         k: \u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(v, \u001b[33m\"\u001b[39m\u001b[33mto\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(v.to) \u001b[38;5;28;01melse\u001b[39;00m v\n\u001b[32m    775\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.data.items()\n\u001b[32m    776\u001b[39m     }\n\u001b[32m    777\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    778\u001b[39m     logger.warning(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAttempting to cast a BatchEncoding to type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(device)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. This is not supported.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def optuna_hp_space(trial):\n",
    "    \"\"\"Bayesian search over the highest-impact hyperparameters.\n",
    "\n",
    "    Searched hyperparameters:\n",
    "      ‚Ä¢ learning_rate\n",
    "      ‚Ä¢ weight_decay\n",
    "      ‚Ä¢ class_weight_pos (for imbalanced classification)\n",
    "      ‚Ä¢ batch_size (16 or 32)\n",
    "\n",
    "    Fixed with educated defaults (not worth searching):\n",
    "      ‚Ä¢ num_train_epochs = 3              (standard for transformer fine-tuning)\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"learning_rate\":                trial.suggest_float(\"learning_rate\", 5e-6, 1e-5, log=True),\n",
    "        \"weight_decay\":                 trial.suggest_float(\"weight_decay\", 0.0, 0.2),\n",
    "        \"per_device_train_batch_size\":  trial.suggest_categorical(\"batch_size\", [16, 32]),\n",
    "        \"class_weight_pos\":             trial.suggest_float(\"class_weight_pos\", 3.0, 8.0),\n",
    "        \"num_train_epochs\":             4,  #trial.suggest_categorical(\"num_train_epochs\", [3, 5]),\n",
    "    }\n",
    "\n",
    "\n",
    "best_hparams = {}\n",
    "\n",
    "for name, model_path in MODEL_CATALOGUE.items():\n",
    "    should_reuse = USE_PREVIOUS_HPARAMS.get(name, False)\n",
    "    \n",
    "    # CASE 1: LOAD SAVED PARAMS\n",
    "    if should_reuse and name in hparams_registry:\n",
    "        print(f\"üìÇ {name:12s} | Loading saved (F1: {hparams_registry[name]['objective']:.4f})\")\n",
    "        best_hparams[name] = hparams_registry[name][\"hyperparameters\"]\n",
    "        continue\n",
    "\n",
    "    # CASE 2: RUN SEARCH\n",
    "    print(f\"\\n{'='*40}\\nüîç Searching: {name}\\n{'='*40}\")\n",
    "    \n",
    "    tokenizer = tokenisers[name]\n",
    "    use_fp16, use_bf16 = get_mixed_precision_flags(name)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./results/{name}\",\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"no\",\n",
    "        metric_for_best_model=\"f1\",\n",
    "        fp16=use_fp16,\n",
    "        bf16=use_bf16,\n",
    "        report_to=\"none\",\n",
    "        disable_tqdm=True # Cleaner logs during HP search\n",
    "    )\n",
    "\n",
    "    trainer = WeightedTrainer(\n",
    "        model_init=lambda: AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=NUM_LABELS),\n",
    "        args=training_args,\n",
    "        train_dataset=tokenize_dataset(train_dataset, tokenizer),\n",
    "        eval_dataset=tokenize_dataset(val_dataset, tokenizer),\n",
    "        compute_metrics=compute_metrics,\n",
    "        data_collator=DataCollatorWithPadding(tokenizer),\n",
    "        class_weights=CLASS_WEIGHTS,\n",
    "    )\n",
    "\n",
    "    best_run = trainer.hyperparameter_search(\n",
    "        direction=\"maximize\",\n",
    "        backend=\"optuna\",\n",
    "        hp_space=optuna_hp_space,\n",
    "        n_trials=N_TRIALS,\n",
    "        pruner=MedianPruner(n_startup_trials=2),\n",
    "        compute_objective=lambda m: m[\"eval_f1\"],\n",
    "    )\n",
    "\n",
    "    # Store results\n",
    "    best_hparams[name] = best_run.hyperparameters\n",
    "    hparams_registry[name] = {\n",
    "        \"objective\": best_run.objective,\n",
    "        \"hyperparameters\": best_run.hyperparameters\n",
    "    }\n",
    "\n",
    "    # Clean up GPU\n",
    "    del trainer\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Final Save\n",
    "# ---------------------------------------------------------------------------\n",
    "with open(HPARAMS_FILE, \"w\") as f:\n",
    "    json.dump(hparams_registry, f, indent=4)\n",
    "\n",
    "print(f\"\\n‚úÖ All hyperparameters synced to {HPARAMS_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e1de03",
   "metadata": {},
   "source": [
    "## 6. Train Each Model with Best Hyperparameters\n",
    "\n",
    "Re-train each model from scratch using the best hyperparameters found above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea15d34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainers = {}  # keep trainers around for prediction\n",
    "\n",
    "for name, model_path in MODEL_CATALOGUE.items():\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"  Final training: {name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    best = best_hparams[name]\n",
    "    hp = best.hyperparameters\n",
    "\n",
    "    tokenizer = tokenisers[name]\n",
    "    train_tok = tokenize_dataset(train_dataset, tokenizer)\n",
    "    val_tok   = tokenize_dataset(val_dataset, tokenizer)\n",
    "\n",
    "    # Build fresh model with best HPs\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_path, num_labels=NUM_LABELS\n",
    "    )\n",
    "\n",
    "    # Verify the model is on the expected device (Trainer will move it, but let's show it)\n",
    "    print(f\"  Model device before Trainer: {next(model.parameters()).device}\")\n",
    "\n",
    "    # Mixed-precision: bf16 when available (all models); fp16 fallback (not DeBERTa)\n",
    "    use_fp16, use_bf16 = get_mixed_precision_flags(name)\n",
    "    print(f\"  Mixed precision ‚Äî fp16: {use_fp16}, bf16: {use_bf16}\")\n",
    "\n",
    "    # Apply best batch size from hp search (backward compatible: default to 32)\n",
    "    batch_size = hp.get(\"batch_size\", 32)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./results/{name}_final\",\n",
    "        num_train_epochs=hp.get(\"num_train_epochs\", 4),                                     \n",
    "        per_device_train_batch_size=batch_size,                 \n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        learning_rate=hp.get(\"learning_rate\", 2e-5),\n",
    "        weight_decay=hp.get(\"weight_decay\", 0.01),\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        save_total_limit=1,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        logging_steps=50,\n",
    "        fp16=use_fp16,\n",
    "        bf16=use_bf16,\n",
    "        warmup_ratio=0.1,\n",
    "        max_grad_norm=1.0,\n",
    "        dataloader_num_workers=2,\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "\n",
    "    # Apply best class weight from hp search\n",
    "    class_w = hp.get(\"class_weight_pos\", 9.0)\n",
    "    final_weights = torch.tensor([1.0, class_w], dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "    print(f\"  Batch size (train & eval)  : {batch_size}\")\n",
    "    print(f\"  Class weight (PCL)        : {class_w:.2f}\")\n",
    "\n",
    "    trainer = WeightedTrainer(\n",
    "        class_weights=final_weights,\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_tok,\n",
    "        eval_dataset=val_tok,\n",
    "        compute_metrics=compute_metrics,\n",
    "        processing_class=tokenizer,\n",
    "        data_collator=DataCollatorWithPadding(tokenizer),\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    # After training, Trainer has moved the model to GPU (if available)\n",
    "    print(f\"  Model device after Trainer : {next(model.parameters()).device}\")\n",
    "\n",
    "    trained_models[name] = model\n",
    "    trainers[name] = trainer\n",
    "    print(f\"‚úì {name} final training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5e4119",
   "metadata": {},
   "source": [
    "## 7. Per-Model Evaluation ‚Äî Results & Confusion Matrices\n",
    "\n",
    "Evaluate each model individually on the **test set**, print classification reports, and plot confusion matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c40e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_model_preds = {}  # {name: np.array of predictions on test set}\n",
    "\n",
    "for name in MODEL_CATALOGUE:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"  Test Evaluation: {name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    tokenizer = tokenisers[name]\n",
    "    test_tok = tokenize_dataset(test_dataset, tokenizer)\n",
    "    trainer = trainers[name]\n",
    "\n",
    "    # Predict on test set\n",
    "    predictions = trainer.predict(test_tok)\n",
    "    preds = np.argmax(predictions.predictions, axis=-1)\n",
    "    labels = predictions.label_ids\n",
    "    per_model_preds[name] = preds\n",
    "\n",
    "    # Classification report\n",
    "    print(f\"\\n{name} ‚Äî Classification Report:\")\n",
    "    print(classification_report(labels, preds, target_names=LABEL_NAMES, digits=4))\n",
    "\n",
    "    # Confusion matrix\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    cm = confusion_matrix(labels, preds)\n",
    "    ConfusionMatrixDisplay(cm, display_labels=LABEL_NAMES).plot(\n",
    "        ax=axes[0], cmap=\"Blues\", colorbar=False\n",
    "    )\n",
    "    axes[0].set_title(f\"{name} ‚Äî Counts\")\n",
    "\n",
    "    cm_norm = confusion_matrix(labels, preds, normalize=\"true\")\n",
    "    ConfusionMatrixDisplay(cm_norm, display_labels=LABEL_NAMES).plot(\n",
    "        ax=axes[1], cmap=\"Blues\", colorbar=False, values_format=\".2%\"\n",
    "    )\n",
    "    axes[1].set_title(f\"{name} ‚Äî Normalised\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e197d25",
   "metadata": {},
   "source": [
    "## 8. Overall Ensemble ‚Äî Majority Vote, Results & Confusion Matrix\n",
    "\n",
    "Each of the 3 models votes; a sample is classified as **PCL** if **2 or more** models agree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7374b6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Majority vote: PCL (1) if >= 2 out of 3 models predict PCL\n",
    "votes = np.stack(list(per_model_preds.values()), axis=0)  # (3, n_test)\n",
    "ensemble_preds = (votes.sum(axis=0) >= 2).astype(int)\n",
    "true_labels = np.array(test_dataset[\"label\"])\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Overall classification report\n",
    "# ---------------------------------------------------------------------------\n",
    "print(\"=\" * 60)\n",
    "print(\"  ENSEMBLE (Majority Vote) ‚Äî Test Set Results\")\n",
    "print(\"=\" * 60)\n",
    "print(classification_report(true_labels, ensemble_preds, target_names=LABEL_NAMES, digits=4))\n",
    "\n",
    "# Per-model vs ensemble summary table\n",
    "rows = []\n",
    "for name, preds in per_model_preds.items():\n",
    "    p, r, f1, _ = precision_recall_fscore_support(true_labels, preds, average=\"binary\", pos_label=1)\n",
    "    acc = accuracy_score(true_labels, preds)\n",
    "    rows.append({\"Model\": name, \"Accuracy\": acc, \"Precision\": p, \"Recall\": r, \"F1\": f1})\n",
    "\n",
    "p, r, f1, _ = precision_recall_fscore_support(true_labels, ensemble_preds, average=\"binary\", pos_label=1)\n",
    "acc = accuracy_score(true_labels, ensemble_preds)\n",
    "rows.append({\"Model\": \"ENSEMBLE\", \"Accuracy\": acc, \"Precision\": p, \"Recall\": r, \"F1\": f1})\n",
    "\n",
    "summary_df = pd.DataFrame(rows).set_index(\"Model\")\n",
    "print(\"\\nSummary comparison:\")\n",
    "display(summary_df.style.format(\"{:.4f}\").highlight_max(axis=0, color=\"lightgreen\"))\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Confusion matrices ‚Äî ensemble\n",
    "# ---------------------------------------------------------------------------\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "cm = confusion_matrix(true_labels, ensemble_preds)\n",
    "ConfusionMatrixDisplay(cm, display_labels=LABEL_NAMES).plot(\n",
    "    ax=axes[0], cmap=\"Oranges\", colorbar=False\n",
    ")\n",
    "axes[0].set_title(\"Ensemble ‚Äî Counts\")\n",
    "\n",
    "cm_norm = confusion_matrix(true_labels, ensemble_preds, normalize=\"true\")\n",
    "ConfusionMatrixDisplay(cm_norm, display_labels=LABEL_NAMES).plot(\n",
    "    ax=axes[1], cmap=\"Oranges\", colorbar=False, values_format=\".2%\"\n",
    ")\n",
    "axes[1].set_title(\"Ensemble ‚Äî Normalised\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Voting agreement heatmap\n",
    "# ---------------------------------------------------------------------------\n",
    "print(\"\\nPer-sample voting agreement:\")\n",
    "agreement = votes.sum(axis=0)\n",
    "for v in [0, 1, 2, 3]:\n",
    "    count = (agreement == v).sum()\n",
    "    print(f\"  {v}/3 models predict PCL: {count} samples ({count/len(agreement)*100:.1f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
